{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `collection.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/utils.py:99: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  warnings.warn(depdoc, DeprecationWarning)\n",
      "Slow version of gensim.models.word2vec is being used\n",
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "import collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_txt = \"corpus\"\n",
    "path_csv = \"corpus_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste mit Dateinamen erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Oct-2016 04:07:21 INFO collection: Creating document list from .txt files ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus/Poe_EurekaAProsePoem.txt',\n",
       " 'corpus/Howard_TheDevilinIron.txt',\n",
       " 'corpus/Lovecraft_TheShunnedHouse.txt',\n",
       " 'corpus/Howard_SchadowsinZamboula.txt',\n",
       " 'corpus/Doyle_AStudyinScarlet.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_txt = collection.create_document_list(path_txt)\n",
    "doclist_txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_document_list in module collection:\n",
      "\n",
      "create_document_list(path, ext='.txt')\n",
      "    Creates a list of files with their full path.\n",
      "    \n",
      "    Args:\n",
      "        path (str): Path to folder, e.g. '/tmp/corpus'.\n",
      "        ext (str): File extension, e.g. '.csv'. Defaults to '.txt'.\n",
      "    \n",
      "    Returns:\n",
      "        list[str]: List of files with full path.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(collection.create_document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Corpus laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Oct-2016 04:07:21 INFO collection: Accessing documents ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230868\n"
     ]
    }
   ],
   "source": [
    "corpus = collection.read_from_txt(doclist_txt)\n",
    "\n",
    "testdoc = next(corpus)\n",
    "print(len(testdoc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Oct-2016 04:07:21 INFO collection: Segmenting documents ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "segments = collection.segmenter(corpus, 1000)\n",
    "testdoc = next(segments)\n",
    "print(len(testdoc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Liste mit CSV-Dateien erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Oct-2016 04:07:21 INFO collection: Creating document list from .csv files ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['corpus_csv/Howard_GodsoftheNorth.txt.csv',\n",
       " 'corpus_csv/Poe_EurekaAProsePoem.txt.csv',\n",
       " 'corpus_csv/Poe_TheMasqueoftheRedDeath.txt.csv',\n",
       " 'corpus_csv/Poe_ThePurloinedLetter.txt.csv',\n",
       " 'corpus_csv/Howard_ShadowsintheMoonlight.txt.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist_csv = collection.create_document_list(path_csv, ext='.csv')\n",
    "doclist_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV Dateien in einen Dataframe einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-Oct-2016 04:07:21 INFO collection: Accessing documents ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ParagraphId  TokenId        Lemma  CPOS NamedEntity\n",
      "0               0        0         gods    NN           _\n",
      "1               0        1           of    PP           _\n",
      "2               0        2          the   ART           _\n",
      "3               0        3        north    NP           _\n",
      "4               1        4           by    PP           _\n",
      "5               1        5       robert    NP           _\n",
      "6               1        6           e.    NP           _\n",
      "7               1        7       howard    NP           _\n",
      "8               2        8            [  CONJ           _\n",
      "9               2        9  transcriber    NP           _\n",
      "10              2       10           's     O           _\n",
      "11              2       11         note    NP           _\n",
      "12              2       12            :  PUNC           _\n",
      "13              2       13   originally   ADV           _\n",
      "14              2       14      publish     V           _\n",
      "15              2       15           in    PP           _\n",
      "16              2       16        march    NP           _\n",
      "17              2       17         1934  CARD           _\n",
      "18              2       18           in    PP           _\n",
      "19              2       19            \"    NN           _\n",
      "20              2       20          the   ART           _\n",
      "21              2       21      fantasy    NP           _\n",
      "22              2       22          fan    NP           _\n",
      "23              2       23            \"    NP           _\n",
      "24              2       24            .  PUNC           _\n",
      "25              2       25         this   ART           _\n",
      "26              2       26        etext    NN           _\n",
      "27              2       27           be     V           _\n",
      "28              2       28      prepare     V           _\n",
      "29              2       29         from    PP           _\n",
      "...           ...      ...          ...   ...         ...\n",
      "3903           68     3903         that   ART           _\n",
      "3904           68     3904        still   ADV           _\n",
      "3905           68     3905       dangle     V           _\n",
      "3906           68     3906         from    PP           _\n",
      "3907           68     3907          his    PR           _\n",
      "3908           68     3908       clench     V           _\n",
      "3909           68     3909        leave     V           _\n",
      "3910           68     3910         fist    NN           _\n",
      "3911           68     3911            ;  PUNC           _\n",
      "3912           68     3912          the   ART           _\n",
      "3913           68     3913       others    NN           _\n",
      "3914           68     3914         gape     V           _\n",
      "3915           68     3915     silently   ADV           _\n",
      "3916           68     3916           at    PP           _\n",
      "3917           68     3917          the   ART           _\n",
      "3918           68     3918         veil    NN           _\n",
      "3919           68     3919           he    PR           _\n",
      "3920           68     3920         hold     V           _\n",
      "3921           68     3921        up--a    NP           _\n",
      "3922           68     3922         wisp    NP           _\n",
      "3923           68     3923           of    PP           _\n",
      "3924           68     3924     gossamer    NN           _\n",
      "3925           68     3925         that   ART           _\n",
      "3926           68     3926           be     V           _\n",
      "3927           68     3927        never   ADV           _\n",
      "3928           68     3928         spin     V           _\n",
      "3929           68     3929           by    PP           _\n",
      "3930           68     3930        human   ADJ           _\n",
      "3931           68     3931      distaff    NN           _\n",
      "3932           68     3932            .  PUNC           _\n",
      "\n",
      "[3933 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['ParagraphId', 'TokenId', 'Lemma', 'CPOS', 'NamedEntity']\n",
    "\n",
    "csv = collection.read_from_csv(doclist_csv, columns)\n",
    "testdoc = next(csv)\n",
    "print(testdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POS-Tags ausw√§hlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter_POS_tags() missing 1 required positional argument: 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c8436228dac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpusCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_POS_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusCSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: filter_POS_tags() missing 1 required positional argument: 'columns'"
     ]
    }
   ],
   "source": [
    "pos_tags = ['ADJ', 'V', 'NN']\n",
    "\n",
    "corpusCSV = collection.filter_POS_tags(csv, pos_tags)\n",
    "\n",
    "testdoc = next(corpusCSV)\n",
    "print(len(testdoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = collection.get_labels(doclist_txt)\n",
    "list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycounter = makeCounter(doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ingest Gensim stuff\n",
    "\n",
    "lda_model = 'out_off/corpus_off.lda'\n",
    "corpus = 'out_off/corpus_off.mm'\n",
    "dictionary = 'out_off/corpus_off.dict'\n",
    "doc_labels = 'out_off/corpus_off_doclabels.txt'\n",
    "interactive  = False\n",
    "\n",
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis.make_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ingest Gensim stuff\n",
    "\n",
    "lda_model = 'out_off/corpus_off.lda'\n",
    "corpus = 'out_off/corpus_off.mm'\n",
    "dictionary = 'out_off/corpus_off.dict'\n",
    "doc_labels = 'out_off/corpus_off_doclabels.txt'\n",
    "interactive  = True\n",
    "\n",
    "vis = collection.Visualization(lda_model, corpus, dictionary, doc_labels, interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interactive = vis.make_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "vis.save_interactive(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
